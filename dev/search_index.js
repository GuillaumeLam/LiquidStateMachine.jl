var documenterSearchIndex = {"docs":
[{"location":"references/#References","page":"References","title":"References","text":"","category":"section"},{"location":"references/","page":"References","title":"References","text":"TODO:","category":"page"},{"location":"references/","page":"References","title":"References","text":"list out references used for this lib; intellectual(papers) + code(repos)","category":"page"},{"location":"structure/#Structure","page":"Structure","title":"Structure","text":"","category":"section"},{"location":"structure/","page":"Structure","title":"Structure","text":"The main sections of the library are as follows:","category":"page"},{"location":"structure/","page":"Structure","title":"Structure","text":"LSM Wrapper\nSpike Train Generator\nUtil functions","category":"page"},{"location":"structure/#LSM-Wrapper","page":"Structure","title":"LSM Wrapper","text":"","category":"section"},{"location":"structure/#Spike-Train-Generator","page":"Structure","title":"Spike Train Generator","text":"","category":"section"},{"location":"structure/#Util-functions","page":"Structure","title":"Util functions","text":"","category":"section"},{"location":"#LiquidStateMachine.jl","page":"Home","title":"LiquidStateMachine.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"LiquidStateMachine.jl is an implementation of the liquid state machine(LSM) popularized by Maass et al. (2002). LSM are the implementation of the conceptual framework reservoir computing using spiking neural networks.","category":"page"},{"location":"documentation/#Documentation","page":"Documentation","title":"Documentation","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"TODO:","category":"page"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"add docstring to code and list stuff here","category":"page"},{"location":"example/#Example","page":"Examples","title":"Example","text":"","category":"section"},{"location":"example/#Minimal-usage","page":"Examples","title":"Minimal usage","text":"","category":"section"},{"location":"example/","page":"Examples","title":"Examples","text":"using LiquidStateMachine\n\nparams = LSM_Params(4,2)\nlsm = LSM(params)\nx = [1,2,5,3]\n\ny = lsm(x)","category":"page"},{"location":"example/#Ultra-Minimal-usage","page":"Examples","title":"Ultra Minimal usage","text":"","category":"section"},{"location":"example/","page":"Examples","title":"Examples","text":"using LiquidStateMachine\n\nLSM(LSM_Params(4,2))([1,2,5,3])","category":"page"},{"location":"example/#ReinforcementLearning.jl-usage","page":"Examples","title":"ReinforcementLearning.jl usage","text":"","category":"section"},{"location":"example/","page":"Examples","title":"Examples","text":"As LiquidStateMachine.jl is differentiable thanks to Flux and Zygote, anywhere a Flux model can be passed, a LiquidStateMachine.jl LSM can be passed:","category":"page"},{"location":"example/","page":"Examples","title":"Examples","text":"using LiquidStateMachine\nusing ReinforcementLearning\nusing StableRNGs\nusing Flux\nusing Flux.Losses\n\nrng = StableRNG(123)\nenv = CartPoleEnv(; T = Float32, rng = rng)\nns, na = length(state(env)), length(action_space(env))\n\nparams = LSM_Params(ns,na,\"cartpole\")\nlsm = LSM(params)\n\npolicy = Agent(\n    policy = QBasedPolicy(\n        learner = BasicDQNLearner(\n            approximator = NeuralNetworkApproximator(\n                model = lsm |> cpu,\n                optimizer = ADAM(),\n            ),\n            batch_size = 32,\n            min_replay_history = 100,\n            loss_func = huber_loss,\n            rng = rng,\n        ),\n        explorer = EpsilonGreedyExplorer(\n            kind = :exp,\n            Ïµ_stable = 0.01,\n            decay_steps = 500,\n            rng = rng,\n        ),\n    ),\n    trajectory = CircularArraySARTTrajectory(\n        capacity = 1000,\n        state = Vector{Float32} => (ns,),\n    ),\n)\nstop_condition = StopAfterStep(10_000, is_show_progress=!haskey(ENV, \"CI\"))\nhook = TotalRewardPerEpisode()\n\nrun(policy, env, stop_condition, hook)","category":"page"}]
}
